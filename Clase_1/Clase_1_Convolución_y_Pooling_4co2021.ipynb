{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase 1 - Convolución y Pooling - 4co2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG9zDZK3LEzN"
      },
      "source": [
        "# Redes Convolucionales\n",
        "\n",
        "En este ejercicio de práctica vamos a implementar las capas convolucionales y de pooling vistas en la teoría, utilizando Numpy. Si bien, ambas capas ya vienen implementadas en las librerías que utilizaremos luego en el resto del curso, resulta interesante poder programarlas desde cero para afianzar el entendimiento de como funcionan en su interior.\n",
        "\n",
        "#### Notación\n",
        "\n",
        "Antes de empezar definimos la notación utilizada cuando trabajamos con este tipo de capas en una red neuronal:\n",
        "\n",
        "- $n_H$, $n_W$ y $n_C$ son la altura, el ancho y número de canales de una determinada capa, respectivamente.\n",
        "\n",
        "- El superíndice $[l]$ denota el número de capa: \n",
        "    - Ejemplo: $a^{[3]}$, $W^{[3]}$ y $b^{[3]}$ son la activación, los pesos y los biases de la $3^{ra}$ capa, respectivamente.\n",
        "\n",
        "- El superíndice $(i)$ denota el número de ejemplo utilizado en el entrenamiento:\n",
        "    - Ejemplo: $x^{(i)}$ es el $i$-ésimo ejemplo de entrada.\n",
        "    \n",
        "- El subíndice $i$ denota el número de elemento en un vector:\n",
        "    - Ejemplo: $a^{[l]}_i$ es la $i$-ésima activación en la capa $l$ (si asumimos una capa Fully Connected).\n",
        "\n",
        "---\n",
        "\n",
        "### Importación de paquetes\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M77LbuQZKtpL"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFgQU8IxOycu"
      },
      "source": [
        "## Capa Convolucional\n",
        "\n",
        "Para implementar una capa convolucional y su forward pass vamos a dividir el trabajo en 3 funciones separadas. En primer lugar, escribiremos una función que nos permita realizar padding con ceros en la cantidad que nosotros deseemos. Luego, haremos una función para realizar el computo de la operación de convolución en sí, es decir, una función que nos retorne el resultado de aplicar la convolución de un filtro determinado en una posición fija de la matriz de entrada. Por último, utilizaremos las dos funciones previas para implementar la operación de convolución completa que realizaria una capa de una red neuronal, sobre un volumen de entrada, con un número determinado de filtros convolucionales.\n",
        "\n",
        "---\n",
        "\n",
        "### Padding con ceros\n",
        "\n",
        "El padding con ceros, o Zero-padding, consiste en agregar ceros en los bordes de la matriz de entrada, lo cual tiene dos razones principales:\n",
        "\n",
        "- Evitar que el ancho y alto de los volumenes dentro de una red neuronal convolucional profunda disminuyan, lo cual limitaría la profundidad que puede tener la red. \n",
        "- Utilizar mejor la información que se encuentra en los bordes de las matrices de entrada en una capa convolucional. Sin la existencia de este padding, pocos valores de la salida dependen de la información en estos bordes.\n",
        "\n",
        "Para implementar facilmente esta operación aprovechamos la funcion [`pad`](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) de Numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWculS4jXaww"
      },
      "source": [
        "# Función para padding con ceros\n",
        "\n",
        "def zero_padding(X, pad):\n",
        "  \"\"\"\n",
        "  Argumentos:\n",
        "    X: Array numpy de entrada con dimensiones (batch_size, n_C, n_H, n_W)\n",
        "    pad: Entero representando la cantidad de filas y columnas que se deben agregar con ceros\n",
        "\n",
        "  Retorna:\n",
        "    X_padded: Array numpy con dimensiones (batch_size, n_C, n_H + 2*pad, n_W + 2*pad)\n",
        "  \"\"\"\n",
        "\n",
        "  X_padded = np.pad(X, ((0,0), (0,0), (pad, pad), (pad, pad)), mode='constant', constant_values = (0,0))\n",
        "\n",
        "  return X_padded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRgHK5NNZPE1"
      },
      "source": [
        "### Operación de convolución\n",
        "\n",
        "En esta segunda función implementaremos la operación de convolución utilizada dentro de las capas convolucionales. Nuestra función, entonces, tomara un recorte del volumen que entra en la capa convolucional, cuyo tamaño es igual al del filtro de pesos, lo convolucionará con dicho filtro (multiplicando elemento a elemento y sumando todos los resultados) y le sumará el bias.\n",
        "\n",
        "Para relizar la suma de todos los elementos en un array de Numpy utilizaremos la función [`sum`](httpshttps://numpy.org/doc/stable/reference/generated/numpy.sum.html://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgPfWEhDcxyq"
      },
      "source": [
        "# Función para realizar la operación de convolución\n",
        "\n",
        "def convolve(X, W, b):\n",
        "  \"\"\"\n",
        "  Argumentos:\n",
        "    X: Array numpy de entrada con dimensiones (filter_size, filter_size, n_C_prev)\n",
        "    W: Array numpy con los pesos de un filtro con dimensiones (filter_size, filter_size, n_C_prev)\n",
        "    b: Entero con el valor de bias de la capa actual\n",
        "\n",
        "  Retorna:\n",
        "    Z: Entero con el valor del resultado\n",
        "  \"\"\"\n",
        "\n",
        "  # Multiplico elemento a elemento el valor de entrada con los pesos del filtro\n",
        "  aux = X * W\n",
        "  # Realizo la suma de todos los elementos\n",
        "  aux = np.sum(aux)\n",
        "  # Le sumo el valor del bias para obtener Z\n",
        "  Z = aux + float(b)\n",
        "\n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtUVeS_hgDOp"
      },
      "source": [
        "### Forward Pass - Capa Convolucional\n",
        "\n",
        "Para realizar el forward pass de una capa convolucional debemos tomar varios filtros y convolucionarlos a lo largo y ancho de todo el volumen de entrada a la capa. El resultado de esta operación será una matriz de dos dimensiones por cada uno de los filtros que contenga la capa, las cuales tenemos que apilar para conformar el volumen de salida.\n",
        "\n",
        "<center>\n",
        "<img width=\"620\" height=\"440\" src=\"https://drive.google.com/uc?id=1H5dI5IlRPktyyIX79uio_dTa7MLTE1oE\">\n",
        "</center>\n",
        "\n",
        "Al implementar esta función debemos tener en cuenta todos los hiperparametros que tienen las capas convolucionales, los cuales influyen tanto en las porciones de la matriz de entrada que tomamos para convolucionar con los filtros de la capa, como así también en las dimensiones del volumen de salida mediante las siguientes formulas:\n",
        "\n",
        "$$ n^{[l]}_H = \\lfloor \\frac{n^{[l-1]}_H - f + 2 \\times p}{s} \\rfloor +1 $$\n",
        "$$ n^{[l]}_W = \\lfloor \\frac{n^{[l-1]}_W - f + 2 \\times p}{s} \\rfloor +1 $$\n",
        "$$ n^{[l]}_C = \\text{Cantidad de filtros de la $l$-ésima capa}$$\n",
        "\n",
        "Comenzamos agregando el padding correspondiente al volumen de entrada. Luego, para cada ejemplo en el batch, seleccionamos ventanas de dicho volumen, respetando los valores de `stride` y `filter_size`, sobre las cuales computaremos la operación de convolución con cada uno de los filtros que compongan la capa. Para saber donde comienza y termina cada una de estas ventanas vamos a utilizar variables internas (`y_start` y `y_end` para el eje vertical, y `x_start` y `x_end` para el horizontal) calculadas a partir de iterar sobre las dimensiones del volumen de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXrBDXQanVtI"
      },
      "source": [
        "# Función para realizar el forward pass de una capa convolucional\n",
        "\n",
        "def conv_forward(layer_input, W, b, stride, padding):\n",
        "  \"\"\"\n",
        "  Argumentos:\n",
        "    layer_input: Array numpy con los valores de entrada a la capa convolucional (batch_size, n_C_prev, n_H_prev, n_W_prev)\n",
        "    W: Array numpy con los pesos de los filtros utilizados en la capa actual (n_C, n_C_prev, filter_size, filter_size)\n",
        "    b: Array numpy con los valores de bias utilizados en la capa actual (1, 1, 1, n_C)\n",
        "    stride: Entero con el valor de stride utilizado en la capa actual.\n",
        "    padding: \n",
        "\n",
        "  Retorna:\n",
        "    Z: Array numpy con los valores de salida de la capa convolucional (batch_size, n_H, n_W, n_C)\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtengo las dimensiones de la entrada\n",
        "  (batch_size, n_C_prev, n_H_prev, n_W_prev) = layer_input.shape\n",
        "\n",
        "  # Obtengo las dimensiones de los filtros\n",
        "  (n_C, n_C_prev, filter_size, filter_size) = W.shape\n",
        "\n",
        "  # Calculo las dimensiones del volumen de salida de la capa actual\n",
        "  n_H = int((n_H_prev + 2*padding - filter_size)/stride + 1)\n",
        "  n_W = int((n_W_prev + 2*padding - filter_size)/stride + 1)\n",
        "\n",
        "  # Inicializo el volumen de salida con ceros\n",
        "  Z = np.zeros([batch_size, n_C, n_H, n_W])\n",
        "\n",
        "  # Agrego padding con ceros al volumen de entrada\n",
        "  layer_input_padded = zero_padding(layer_input, padding)\n",
        "\n",
        "  # Comienzo iterando sobre cada ejemplo del batch\n",
        "  for i in range(batch_size):\n",
        "\n",
        "    # Itero sobre el eje vertical del volumen de salida\n",
        "    for h in range(n_H):\n",
        "      # Calculo las coordenadas verticales de inicio y fin de la ventana sobre la que aplicaremos el filtro\n",
        "      y_start = stride * h\n",
        "      y_end = y_start + filter_size\n",
        "\n",
        "      # Itero sobre el eje horizontal del volumen de salida\n",
        "      for w in range(n_W):\n",
        "        # Calculo las coordenadas horizontales de inicio y fin de la ventana sobre la que aplicaremos el filtro\n",
        "        x_start = stride * w\n",
        "        x_end = x_start + filter_size\n",
        "\n",
        "        # Extraigo la ventana para calcular la convolucion, del volumen de entrada con padding\n",
        "        slice_from_input_padded = layer_input_padded[i, :, y_start:y_end, x_start:x_end]\n",
        "        \n",
        "        # Itero sobre la cantidad de canales del volumen de salida\n",
        "        for c in range(n_C):\n",
        "\n",
        "          # Obtengo el valor del filtro y bias del canal correspondiente\n",
        "          filter = W[c, :, :, :]\n",
        "          bias = b[c]\n",
        "\n",
        "          # Computo la operación de convolución para esta ventana\n",
        "          Z[i, c, h, w] = convolve(slice_from_input_padded, filter, bias)\n",
        "  \n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyXDGLBr_0fw"
      },
      "source": [
        "# Dimensiones de la entrada\n",
        "batch_size = 10\n",
        "input_height, input_width = (7, 7)\n",
        "input_channels = 4\n",
        "\n",
        "# Dimensiones de la convolucional\n",
        "filters = 8\n",
        "filter_size = 3\n",
        "stride = 2\n",
        "pad = 1\n",
        "\n",
        "# Variables de prueba\n",
        "test_array = np.random.randn(batch_size, input_channels, input_height, input_width)\n",
        "W = np.random.randn(filters, input_channels, filter_size, filter_size)\n",
        "b = np.random.randn(filters)\n",
        "\n",
        "\n",
        "conv_result = conv_forward(test_array, W, b, stride, pad)\n",
        "conv_result_pyt = torch.nn.functional.conv2d(torch.tensor(test_array), torch.tensor(W), torch.tensor(b), stride, pad)\n",
        "\n",
        "assert(conv_result.shape == conv_result_pyt.shape)\n",
        "print(\"Convolución: Result shape: {}\".format(conv_result.shape))\n",
        "print(\"Convolución: Result value: {}\".format(conv_result[1, 1, 1, 1]))\n",
        "print(\"Convolución: Result shape: {}\".format(conv_result_pyt.shape))\n",
        "print(\"Convolución: Result value: {}\".format(conv_result_pyt[1, 1, 1, 1]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVpA_BlpCD-9"
      },
      "source": [
        "## Capa Pooling\n",
        "\n",
        "La capa de pooling realiza una operación más simple que la capa convolucional. En este caso, simplemente se reducen las dimensiones verticales y horizontales del volumen de entrada, sin afectar su profundidad (ya que no existen los filtros). Dado que las capas de pooling pueden ser de tipo \"Max-Pooling\" o \"Average-Pooling\", implementaremos a continuación, una función para cada tipo de operación.\n",
        "\n",
        "![Example-of-max-pooling-and-average-pooling-operations-In-this-example-a-4x4-image-is.png](https://drive.google.com/uc?id=1QjV72N9yAlgxwAyzRKOzjjH6rqkHfTFB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyC68ZxpHf1S"
      },
      "source": [
        "def max_pooling_forward(layer_input, filter_size, stride):\n",
        "  \"\"\"\n",
        "  Argumentos:\n",
        "    layer_input: Array numpy con los valores de entrada a la capa max-pooling (batch_size, n_C_prev, n_H_prev, n_W_prev)\n",
        "    filter_size: Entero con el valor de tamaño de filtro utilizado en la capa actual. \n",
        "    stride: Entero con el valor de stride utilizado en la capa actual.\n",
        "\n",
        "  Retorna:\n",
        "    Z: Array numpy con los valores de salida de la capa max-pooling (batch_size, n_C, n_H, n_W)\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtengo las dimensiones de la entrada\n",
        "  (batch_size, n_C_prev, n_H_prev, n_W_prev) = layer_input.shape\n",
        "\n",
        "  # Calculo las dimensiones del volumen de salida de la capa actual\n",
        "  n_H = int(1 + (n_H_prev - filter_size) / stride)\n",
        "  n_W = int(1 + (n_W_prev - filter_size) / stride)\n",
        "  n_C = n_C_prev\n",
        "\n",
        "  # Inicializo el volumen de salida con ceros\n",
        "  Z = np.zeros([batch_size, n_C, n_H, n_W])\n",
        "\n",
        "  # Comienzo iterando sobre cada ejemplo del batch\n",
        "  for i in range(batch_size):\n",
        "\n",
        "    # Itero sobre el eje vertical del volumen de salida\n",
        "    for h in range(n_H):\n",
        "      # Calculo las coordenadas verticales de inicio y fin de la ventana\n",
        "      y_start = stride * h\n",
        "      y_end = y_start + filter_size\n",
        "\n",
        "      # Itero sobre el eje horizontal del volumen de salida\n",
        "      for w in range(n_W):\n",
        "        # Calculo las coordenadas horizontales de inicio y fin de la ventana\n",
        "        x_start = stride * w\n",
        "        x_end = x_start + filter_size\n",
        "        \n",
        "        # Itero sobre la cantidad de canales del volumen de salida\n",
        "        for c in range(n_C):\n",
        "\n",
        "          # Obtengo el maximo\n",
        "          Z[i, c, h, w] = np.max(layer_input[i, c, y_start:y_end, x_start:x_end])\n",
        "\n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XdJb5Eh0OV2"
      },
      "source": [
        "def average_pooling_forward(layer_input, filter_size, stride):\n",
        "  \"\"\"\n",
        "  Argumentos:\n",
        "    layer_input: Array numpy con los valores de entrada a la capa max-pooling (batch_size, n_C_prev, n_H_prev, n_W_prev)\n",
        "    filter_size: Entero con el valor de tamaño de filtro utilizado en la capa actual. \n",
        "    stride: Entero con el valor de stride utilizado en la capa actual.\n",
        "\n",
        "  Retorna:\n",
        "    Z: Array numpy con los valores de salida de la capa average-pooling (batch_size, n_C, n_H, n_W)\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtengo las dimensiones de la entrada\n",
        "  (batch_size, n_C_prev, n_H_prev, n_W_prev) = layer_input.shape\n",
        "\n",
        "  # Calculo las dimensiones del volumen de salida de la capa actual\n",
        "  n_H = int(1 + (n_H_prev - filter_size) / stride)\n",
        "  n_W = int(1 + (n_W_prev - filter_size) / stride)\n",
        "  n_C = n_C_prev\n",
        "\n",
        "  # Inicializo el volumen de salida con ceros\n",
        "  Z = np.zeros([batch_size, n_C, n_H, n_W])\n",
        "\n",
        "  # Comienzo iterando sobre cada ejemplo del batch\n",
        "  for i in range(batch_size):\n",
        "\n",
        "    # Itero sobre el eje vertical del volumen de salida\n",
        "    for h in range(n_H):\n",
        "      # Calculo las coordenadas verticales de inicio y fin de la ventana\n",
        "      y_start = stride * h\n",
        "      y_end = y_start + filter_size\n",
        "\n",
        "      # Itero sobre el eje horizontal del volumen de salida\n",
        "      for w in range(n_W):\n",
        "        # Calculo las coordenadas horizontales de inicio y fin de la ventana\n",
        "        x_start = stride * w\n",
        "        x_end = x_start + filter_size\n",
        "        \n",
        "        # Itero sobre la cantidad de canales del volumen de salida\n",
        "        for c in range(n_C):\n",
        "\n",
        "          # Obtengo el maximo\n",
        "          Z[i, c, h, w] = np.mean(layer_input[i, c, y_start:y_end, x_start:x_end])\n",
        "\n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRATm8w91D53"
      },
      "source": [
        "# Dimensiones de la entrada\n",
        "batch_size = 10\n",
        "input_height, input_width = (10, 10)\n",
        "input_channels = 3\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "test_array = np.random.randn(batch_size, input_channels, input_height, input_width)\n",
        "stride = 2\n",
        "filter_size = 2\n",
        "\n",
        "max_result = max_pooling_forward(test_array, filter_size, stride)\n",
        "max_result_pyt = torch.nn.functional.max_pool2d(torch.tensor(test_array), filter_size, stride)\n",
        "\n",
        "assert(max_result.shape == max_result_pyt.shape)\n",
        "print(\"Max-Pooling: Result shape: {}\".format(max_result.shape))\n",
        "print(\"Max-Pooling: Result value: {}\".format(max_result[0, 0, 0, 0]))\n",
        "print(\"Max-Pooling: Result shape: {}\".format(max_result_pyt.shape))\n",
        "print(\"Max-Pooling: Result value: {}\".format(max_result_pyt[0, 0, 0, 0]))\n",
        "\n",
        "average_result = average_pooling_forward(test_array, filter_size, stride)\n",
        "average_result_pyt = torch.nn.functional.avg_pool2d(torch.tensor(test_array), filter_size, stride)\n",
        "\n",
        "assert(max_result.shape == average_result_pyt.shape)\n",
        "print(\"Average-Pooling: Result shape: {}\".format(average_result.shape))\n",
        "print(\"Average-Pooling: Result value: {}\".format(average_result[0, 0, 0, 0]))\n",
        "print(\"Average-Pooling: Result shape: {}\".format(average_result_pyt.shape))\n",
        "print(\"Average-Pooling: Result value: {}\".format(average_result_pyt[0, 0, 0, 0]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}