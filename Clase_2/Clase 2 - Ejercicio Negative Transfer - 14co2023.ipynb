{"cells":[{"cell_type":"markdown","metadata":{"id":"NJWHjAloWHNM"},"source":["# Ejercicio Negative Transfer\n","\n","El objetivo de este ejercicio es visualizar el efecto del Negative Transfer cuando se aplica Transfer Learning. Para ello, se debera entrenar una red neuronal, cuya arquitectura esta definida por la clase `ConvModel` de la celda que se encuentra a continuacion, utilizando el dataset ya conocido de imagenes de perros y gatos. Luego, se utilizara dicho modelo preentrenado para hacer transfer learning sobre un dataset de imagenes de frutas (banana y melon concretamente). Este dataset cuenta con 900 imagenes de cada clase en el set de entrenamiento, y 100 en el de testeo. \n","\n","Dada la poca relacion que hay entre imagenes de perros y gatos vs bananas y melones, se espera entonces que el entrenamiento utilizando Transfer Learning tenga resultados pobres, comparados con los obtenidos por el modelo base durante su entrenamiento.\n","\n","Para probar esto se debe:\n","\n","- Entrenar la arquitectura con el dataset de perros y gatos durante unas 40 o 50 epocas, aplicando Data Augmentation para evitar el sobreentrenamiento. Una vez que se logre un resultado satisfactorio (accuracy por encima de 75%), se puede guardar dicho modelo para utilizarlo como base para el Transfer Learning.\n","- Reemplazar la ultima capa del modelo preentrenado y re-entrenar utilizando el dataset de frutas. Realizar el entrenamiento durante unas 20 epocas, utilizando un learning rate menor al del punto anterior. Observar los resultados obtenidos y compararlos con los del punto anterior.\n","- Por ultimo, entrenar la misma arquitectura, desde cero, utilizando el dataset de frutas. Observar los resultados obtenidos y compararlos con los del punto anterior."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSDFk1ctX20g","outputId":"5bd0afc6-d5aa-49cb-849d-2da7692a5cb1","executionInfo":{"status":"ok","timestamp":1678429349949,"user_tz":480,"elapsed":19987,"user":{"displayName":"Juan Ignacio Cavalieri","userId":"15252118238119694163"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.6/518.6 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.13.1+cu116)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.4.0)\n","Collecting gdown\n","  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (4.0.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.4.0\n","    Uninstalling gdown-4.4.0:\n","      Successfully uninstalled gdown-4.4.0\n","Successfully installed gdown-4.6.4\n"]}],"source":["!pip install torchmetrics\n","!pip install --upgrade --no-cache-dir gdown"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QCxrrCdVSKet","executionInfo":{"status":"ok","timestamp":1678429357246,"user_tz":480,"elapsed":7306,"user":{"displayName":"Juan Ignacio Cavalieri","userId":"15252118238119694163"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import random\n","import os\n","\n","import torch\n","import torchvision\n","import torchsummary\n","import torchmetrics\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"vofKabMoLn7F"},"source":["### Descargar datasets de perros y gatos y de frutas"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4S2_NugX20j","outputId":"92259168-b6fd-48fe-b0d2-141ade7a40d3","executionInfo":{"status":"ok","timestamp":1678429368637,"user_tz":480,"elapsed":11410,"user":{"displayName":"Juan Ignacio Cavalieri","userId":"15252118238119694163"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1bx73wWKNgxFZ6sSFSeaKBVcuGtdraKh-\n","To: /content/perros_y_gatos.zip\n","100% 90.8M/90.8M [00:02<00:00, 41.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1S2bnSwFrV3GKjGaLs7Br7_0iIhXLR_us\n","To: /content/frutas.zip\n","100% 75.8M/75.8M [00:02<00:00, 34.4MB/s]\n"]}],"source":["# Descarga dataset de perros y gatos\n","!gdown 1bx73wWKNgxFZ6sSFSeaKBVcuGtdraKh-\n","!unzip perros_y_gatos.zip > /dev/null\n","\n","# Descarga dataset de frutas\n","!gdown 1S2bnSwFrV3GKjGaLs7Br7_0iIhXLR_us\n","!unzip frutas.zip > /dev/null"]},{"cell_type":"markdown","metadata":{"id":"oOOjs1ZmX20m"},"source":["### Función de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icZqJ2wNX20n"},"outputs":[],"source":["def train(model, optimizer, criterion, metric, data, epochs, tb_writer=None):\n","\n","    train_loader = data[\"train\"]\n","    valid_loader = data[\"valid\"]\n","\n","    train_writer = tb_writer[\"train\"]\n","    valid_writer = tb_writer[\"valid\"]\n","\n","    if tb_writer:\n","        train_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n","        valid_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n","\n","    if torch.cuda.is_available():\n","        model.to(\"cuda\")\n","        metric.to(\"cuda\")\n","\n","    train_loss = []\n","    train_acc = []\n","    valid_loss = []\n","    valid_acc = []\n","\n","    for epoch in range(epochs):\n","\n","        # Pongo el modelo en modo entrenamiento\n","        model.train()\n","\n","        epoch_train_loss = 0.0\n","        epoch_train_accuracy = 0.0\n","\n","        for train_data, train_target in train_loader:\n","            \n","            if torch.cuda.is_available():\n","                train_data = train_data.to(\"cuda\")\n","                train_target = train_target.to(\"cuda\")\n","\n","            optimizer.zero_grad()\n","            output = model(train_data.float())\n","            loss = criterion(output, train_target)\n","            epoch_train_loss += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","\n","            accuracy = metric(output, train_target)\n","            epoch_train_accuracy += accuracy.item()\n","\n","        epoch_train_loss = epoch_train_loss / len(train_loader)\n","        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n","        train_loss.append(epoch_train_loss)\n","        train_acc.append(epoch_train_accuracy)\n","\n","        # Pongo el modelo en modo testeo\n","        model.eval()\n","\n","        epoch_valid_loss = 0.0\n","        epoch_valid_accuracy = 0.0\n","\n","        for valid_data, valid_target in valid_loader:\n","            if torch.cuda.is_available():\n","                valid_data = valid_data.to(\"cuda\")\n","                valid_target = valid_target.to(\"cuda\")\n","\n","            output = model(valid_data.float())\n","            epoch_valid_loss += criterion(output, valid_target).item()\n","            epoch_valid_accuracy += metric(output, valid_target).item()\n","            \n","        epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n","        epoch_valid_accuracy = epoch_valid_accuracy / len(valid_loader)\n","        valid_loss.append(epoch_valid_loss)\n","        valid_acc.append(epoch_valid_accuracy)\n","\n","        print(\"Epoch: {}/{} - Train loss {:.6f} - Train Accuracy {:.6f} - Valid Loss {:.6f} - Valid Accuracy {:.6f}\".format(\n","        epoch+1, epochs, epoch_train_loss, epoch_train_accuracy, epoch_valid_loss, epoch_valid_accuracy))\n","\n","        if tb_writer:\n","            train_writer.add_scalar(\"loss\", epoch_train_loss, epoch)\n","            valid_writer.add_scalar(\"loss\", epoch_valid_loss, epoch)\n","            train_writer.add_scalar(\"accuracy\", epoch_train_accuracy, epoch)\n","            valid_writer.add_scalar(\"accuracy\", epoch_valid_accuracy, epoch)\n","            train_writer.flush()\n","            valid_writer.flush()\n","\n","    history = {}\n","    history[\"train_loss\"] = train_loss\n","    history[\"train_acc\"] = train_acc\n","    history[\"valid_loss\"] = valid_loss\n","    history[\"valid_acc\"] = valid_acc\n","\n","    return history"]},{"cell_type":"markdown","metadata":{"id":"1xSRmSFTLn7I"},"source":["### Arquitectura de red neuronal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-sKFjwbLn7I"},"outputs":[],"source":["CANTIDAD_CLASES = 2\n","ANCHO_IMAGENES = 150\n","ALTO_IMAGENES = 150"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeQE6EMbX20q"},"outputs":[],"source":["class ConvModel(torch.nn.Module):\n","    def __init__(self, output_units):\n","        super().__init__()\n","        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same')\n","        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same')\n","        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n","        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n","        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.fc1 = torch.nn.Linear(in_features=10368, out_features=256)\n","        self.fc2 = torch.nn.Linear(in_features=256, out_features=output_units)\n","\n","    def forward(self, x):\n","        x = self.pool1(torch.relu(self.conv1(x)))\n","        x = self.pool2(torch.relu(self.conv2(x)))\n","        x = self.pool3(torch.relu(self.conv3(x)))\n","        x = self.pool4(torch.relu(self.conv4(x)))\n","        x = torch.flatten(x, 1)\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","conv_model = ConvModel(CANTIDAD_CLASES)\n","\n","# Si hay una GPU disponible muevo el modelo allí para aprovechar ese recurso\n","if torch.cuda.is_available():\n","    conv_model.to(\"cuda\")\n","\n","torchsummary.summary(conv_model, (3, ANCHO_IMAGENES, ALTO_IMAGENES))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ceia-2qPzDgTX","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"6a7e264b0185234a6d090a42ff6d01e38825180e16d17b7c5c45b22f8dc26b79"}}},"nbformat":4,"nbformat_minor":0}